RUST_LOG="info,actix_web_prom=error"
LOG_FORMAT="pretty"
INFERENCE_HOSTNAME="0.0.0.0"
INFERENCE_PORT="8090"
CORS_ALLOWED_ORIGINS="*"

# HuggingFace endpoint (for Artifactory proxy or local mirror in airgapped environments)
# HF_ENDPOINT="https://huggingface.co"

# Comma-separated list of allowed models (REQUIRED)
# Set to '*' for all models, or a specific list
# If empty or not set, the server will fail to start
INFERENCE_ALLOWED_EMBEDDING_MODELS="snowflake/snowflake-arctic-embed-s,snowflake/snowflake-arctic-embed-xs"
#INFERENCE_ALLOWED_RERANK_MODELS="jinaai/jina-reranker-v2-base-multilingual"


SERVER_SSL_ENABLED="false"
# SERVER_SSL_CERT_PATH="/path/to/cert.pem"
# SERVER_SSL_KEY_PATH="/path/to/key.pem"

OTEL_EXPORTER_OTLP_ENDPOINT="http://localhost:4317"
SERVICE_NAME="embedding-inference-api"


CUDA_VISIBLE_DEVICES=0
ORT_CUDA_MEM_ARENA_SHRINK=1
EMBEDDING_REQUEST_LIMIT=500
INFERENCE_QUEUE_TIMEOUT_MS="5000"
INFERENCE_MAX_CONCURRENT_REQUESTS="4"
