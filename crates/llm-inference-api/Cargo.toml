[package]
name = "llm-inference-api"
version = "0.1.0"
edition = "2024"
authors = ["Jonathan Poisson"]
readme = "README.md"
license-file = "LICENSE"

[[bin]]
name = "llm-inference-api"

[features]
default = []

[dependencies]
semantic-explorer-core = { workspace = true }
actix-web = { workspace = true }
actix-cors = { workspace = true }
actix-web-prom = { workspace = true }
utoipa = { workspace = true }
utoipa-actix-web = { workspace = true }
utoipa-swagger-ui = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
anyhow = { workspace = true }
dotenvy = { workspace = true }
tracing = { workspace = true }
tokio = { workspace = true }
futures = { workspace = true }
async-stream = { workspace = true }
mistralrs = { git = "https://github.com/EricLBuehler/mistral.rs", tag = "v0.7.0", features = ["cuda", "flash-attn", "cudnn"] }
hf-hub = { version = "0.4.3", default-features = false, features = ["ureq"] }

[lints.clippy]
enum_glob_use = "deny"

[lints.rust]
unsafe_code = "forbid"
